# -*- coding: utf-8 -*-
"""extract_keywords.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TgC86pwkAusAg3Xgf8512YNS8Dq7ZltU
"""

!pip install git+https://github.com/boudinfl/pke.git
!pip install -U ginza ja_ginza_electra
!pip install -U spacy
!pip install nltk
!python -m nltk.downloader stopwords
!python -m spacy download ja_core_news_sm
!pip install --upgrade scipy

import pandas as pd
import ginza
import nltk
import spacy
import scipy
import pke
import json
from spacy.lang import ja
# print(scipy.__version__)


pke.base.stopwords['ja_ginza_electra'] = 'japanese'
stopwords = list(ja.STOP_WORDS)
nltk.corpus.stopwords.words_org = nltk.corpus.stopwords.words
nltk.corpus.stopwords.words = lambda lang : stopwords if lang == 'japanese' else nltk.corpus.stopwords.words_olg(lang)

def extract_phrases(data):
  
  extractor = pke.unsupervised.TopicRank()
  extractor.load_document(input=data, language='ja', normalization=None)
  extractor.candidate_selection(pos={"NOUN", "PROPN", "ADJ", "NUM"})
  extractor.candidate_weighting()

  kwds_scrs = extractor.get_n_best(n=5)

  out = []
  for word in kwds_scrs:
    tmp = {'id': '', 'group': 0, 'text': '', 'association': 0}
    tmp['id'] = word[0]
    tmp['text'] = data.text
    tmp['association'] = word[1]

    out.append(tmp)

  with open('./test.json', 'w') as f:
    json.dump(out, f, indent=2, ensure_ascii=False)

org = pd.read_csv('/content/drive/MyDrive/1567_14913.csv',encoding="shift-jis")

text = []
for word in org['メロス']:
    # text_list = text.split(' ')
    text.append(word)
sentences = ''.join(text)
nlp = spacy.load('ja_core_news_sm')
doc = nlp(sentences)

extract_phrases(doc)

